{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, getopt\n",
    "from psutil import virtual_memory\n",
    "sys.path.insert(0, \"cdc/src/\")\n",
    "from NoteDeid import *\n",
    "from NoteConceptParser import *\n",
    "from Converter import *\n",
    "from MLPipeline import *\n",
    "from D2v import *\n",
    "from RPDR import *\n",
    "def evaluate(argv):    \n",
    "    argv=argv.split()\n",
    "    mem = virtual_memory().total / 1024.**3\n",
    "    \n",
    "    workdir = datadir = labelfile = deid = parser = parserdir = ctakessetup = utsname = utspw = \\\n",
    "    ctakesminmem = ctakesmaxmem = convert = model = feature = vec_represent = algorithm = \\\n",
    "    balanced_class = repeat = cv = rpdr = ''\n",
    "    \n",
    "    try:\n",
    "        opts, args = getopt.getopt(argv, \"w:d:l:i:p:q:s:n:o:e:g:c:m:f:v:a:b:r:k:x:h\", \\\n",
    "        [\"workdir=\", \"datadir=\", \"labelfile=\", \"deid=\", \"parser=\", \"parserdir=\", \"ctakessetup=\", \"utsname=\", \\\n",
    "        \"utspw=\", \"ctakesminmem=\", \"ctakesmaxmem=\", \"convert=\", \"model=\", \"feature=\", \"vec_represent=\", \\\n",
    "        \"algorithm=\", \"balancedclass=\", \"repeat=\", \"cv=\", \"rpdr=\", \"help\"])\n",
    "    except getopt.GetoptError:\n",
    "        usage('pipeline.py -wd <workdir> -dd <datadir> -lf <labelfile> -d <T/F> -p <T/F> -pd <parserdir> -cset <T/F> -un <utsname> -upw <utspw> -mnm <ctakesminmem> -mxm <ctakesmaxmem> -c <convert> -m <T/F> -f <feature> -v <vec_represent> -a <algorithm> -bc <T/F> -r <repeat> -cv <cv> -h')\n",
    "        sys.exit(2)\n",
    "    \n",
    "    for opt, arg in opts:\n",
    "        if opt == (\"-h\", \"--help\"):\n",
    "            usage('pipeline.py -wd <workdir> -dd <datadir> -lf <labelfile> -d <T/F> -p <T/F> -pd <parserdir> -cset <T/F> -un <utsname> -upw <utspw> -mnm <ctakesminmem> -mxm <ctakesmaxmem> -c <convert> -m <T/F> -f <feature> -v <vec_represent> -a <algorithm> -bc <T/F> -r <repeat> -cv <cv> -h')\n",
    "            sys.exit()\n",
    "        elif opt in (\"-w\", \"--workdir\"):\n",
    "            workdir = arg\n",
    "        elif opt in (\"-d\", \"--datadir\"):\n",
    "            datadir = arg\n",
    "        elif opt in (\"-l\", \"--labelfile\"):\n",
    "            labelfile = arg\n",
    "        elif opt in (\"-i\", \"--deid\"):\n",
    "            deid = arg\n",
    "        elif opt in (\"-s\", \"--ctakessetup\"):\n",
    "            ctakessetup = arg\n",
    "        elif opt in (\"-n\", \"--utsname\"):\n",
    "            utsname = arg\n",
    "        elif opt in (\"-o\", \"--utspw\"):\n",
    "            utspw = arg\n",
    "        elif opt in (\"-e\", \"--ctakesminmem\"):\n",
    "            ctakesminmem = arg\n",
    "        elif opt in (\"-g\", \"--ctakesmaxmem\"):\n",
    "            ctakesmaxmem = arg\n",
    "        elif opt in (\"-m\", \"--model\"):\n",
    "            model = arg\n",
    "        elif opt in (\"-f\", \"--feature\"):\n",
    "            feature = arg\n",
    "        elif opt in (\"-v\", \"--vec_represent\"):\n",
    "            vec_represent = arg\n",
    "        elif opt in (\"-a\", \"--algorithm\"):\n",
    "            algorithm = arg\n",
    "        elif opt in (\"-b\", \"--balancedclass\"):\n",
    "            balanced_class = arg\n",
    "        elif opt in (\"-r\", \"--repeat\"):\n",
    "            repeat = int(arg)\n",
    "        elif opt in (\"-k\", \"--cv\"):\n",
    "            cv = int(arg)\n",
    "        elif opt in (\"-x\", \"--rpdr\"):\n",
    "            xx = arg\n",
    "    \n",
    "    print 'Working directory        :', workdir\n",
    "    print 'Data directory           :', datadir\n",
    "    print 'Label file location      :', labelfile\n",
    "    print 'Running deidentification :', deid\n",
    "    print 'Setting up cTAKES        :', ctakessetup\n",
    "    print 'UTS username             :', utsname\n",
    "    print 'UTS password             :', utspw\n",
    "    print 'cTAKES minimal memory    :', ctakesminmem\n",
    "    print 'cTAKES maximal memory    :', ctakesmaxmem\n",
    "    print 'Data conversion from     :', convert\n",
    "    print 'Modeling                 :', model\n",
    "    print 'Selected feature         :', feature\n",
    "    print 'Vector representation    :', vec_represent\n",
    "    print 'Algorithm                :', algorithm\n",
    "    print 'Class balancing          :', balanced_class\n",
    "    print 'Repeat time              :', repeat\n",
    "    print 'k-fold cross-validation  :', cv\n",
    "\n",
    "    if os.path.exists(workdir) == False:\n",
    "        os.system(\"mkdir \" + workdir + \"; cd \" + workdir + \"; mkdir data; mkdir model; mkdir result; cd ..\")\n",
    "        \n",
    "    os.chdir(workdir)\n",
    "    \n",
    "    if datadir == '' and 'xx' not in locals():\n",
    "        datadir = workdir + 'data/'\n",
    "        print \"No data provided, use sample data\"\n",
    "        os.system(\"wget https://github.com/ckbjimmy/ckbjimmy.github.io/raw/master/files/sample.tar.gz; \\\n",
    "        wget https://raw.githubusercontent.com/ckbjimmy/ckbjimmy.github.io/master/files/label.txt; \\\n",
    "        tar -xzf sample.tar.gz; mv sample/ data/xml/; mv label.txt data/label.txt; rm sample.tar.gz\")\n",
    "        labelfile = datadir + 'label.txt'\n",
    "        \n",
    "    if deid == \"T\":\n",
    "        try: \n",
    "            RunDeid(folder=datadir, deidDir=workdir + 'deid-1.1')\n",
    "        except:\n",
    "            print \"Downloading deid package from physionet\"\n",
    "            os.chdir(workdir)\n",
    "            os.system(\"wget https://www.physionet.org/physiotools/sources/deid/deid-1.1.tar.gz; \\\n",
    "        tar -xzf deid-1.1.tar.gz; rm deid-1.1.tar.gz; cd deid-1.1; rm *.txt; cd ..\")\n",
    "            try:\n",
    "                RunDeid(folder=datadir, deidDir=workdir + 'deid-1.1')\n",
    "            except:\n",
    "                print \"No free text files for deidentification\"\n",
    "                sys.exit(2)\n",
    "\n",
    "    if model == \"T\":\n",
    "        if convert == \"idash\":\n",
    "            MLPipeline(path=workdir, data=workdir + 'data/data.txt', label=workdir + 'data/label.txt', \\\n",
    "            vec=vec_represent, alg = algorithm, cwt=balanced_class, feature=feature, rep=repeat, k=cv)\n",
    "        elif convert == \"rpdr\":\n",
    "            rpdr_param = xx.split('+')\n",
    "            RPDR(path=workdir, lab=rpdr_param[1], num=rpdr_param[2])\n",
    "            MLPipeline(path=workdir, data=workdir + 'data/data.txt', label=workdir + 'data/label.txt', \\\n",
    "            vec=vec_represent, alg = algorithm, cwt=balanced_class, feature=feature, rep=repeat, k=cv)\n",
    "        else:\n",
    "            MLPipeline(path=workdir, data=workdir + 'data/data.txt', label=labelfile, \\\n",
    "            vec=vec_represent, alg = algorithm, cwt=balanced_class, feature=feature, rep=repeat, k=cv)\n",
    "        \n",
    "    print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory        : /Users/zebinkang/Github/scalable_text_analysis/test/\n",
      "Data directory           : /Users/zebinkang/Github/scalable_text_analysis/test/data/data.txt\n",
      "Label file location      : /Users/zebinkang/Github/scalable_text_analysis/test/data/label.txt\n",
      "Running deidentification : \n",
      "Setting up cTAKES        : \n",
      "UTS username             : \n",
      "UTS password             : \n",
      "cTAKES minimal memory    : \n",
      "cTAKES maximal memory    : \n",
      "Data conversion from     : \n",
      "Modeling                 : T\n",
      "Selected feature         : sg\n",
      "Vector representation    : freq\n",
      "Algorithm                : l1+l2+nb+svmlin+svmsgd+mlp_lbfgs+mlp_sgd+mlp_adam\n",
      "Class balancing          : None\n",
      "Repeat time              : 1\n",
      "k-fold cross-validation  : 5\n",
      "--- Data preprocessing ---\n",
      "Label encoding\n",
      "--- Vector representation ---\n",
      "One-hot representation\n",
      "Convert to sparse matrix\n",
      "(431, 4531)\n",
      "Feature selection (N)\n",
      "Topic modeling (N)\n",
      "--- Supervised learning with repeated cross-validation ---\n",
      "input X, y, algorithm, rep, k\n",
      "Model: sg | LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) | rep1 | cv1 | time: 2.03404712677 sec\n",
      "(0.9101123595505618, 0.91053476387598198, 0.9101123595505618, 0.90959050777362982, 0.94538876179240372)\n",
      "Model: sg | LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) | rep1 | cv2 | time: 2.02783894539 sec\n",
      "(0.88505747126436785, 0.90656376357275903, 0.88505747126436785, 0.88419303131946814, 0.92951670040485812)\n",
      "Model: sg | LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) | rep1 | cv3 | time: 2.02970504761 sec\n",
      "(0.89411764705882357, 0.89939309056956118, 0.89411764705882357, 0.88939119049845705, 0.93029088996830933)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: sg | LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) | rep1 | cv4 | time: 2.0318031311 sec\n",
      "(0.82352941176470584, 0.82839215686274503, 0.82352941176470584, 0.82400772430184188, 0.88937534098824422)\n",
      "Model: sg | LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) | rep1 | cv5 | time: 2.02887010574 sec\n",
      "(0.89411764705882357, 0.89694864612511671, 0.89411764705882357, 0.89284744667097615, 0.9315680417150406)\n",
      "Model: sg | LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) | rep1 | cv1 | time: 2.03126597404 sec\n",
      "(0.9213483146067416, 0.92065372829417769, 0.9213483146067416, 0.92070027815718369, 0.95073730617208885)\n",
      "Model: sg | LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) | rep1 | cv2 | time: 2.02559995651 sec\n",
      "(0.89655172413793105, 0.89555903866248687, 0.89655172413793105, 0.89528886350475545, 0.9342301212106251)\n",
      "Model: sg | LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) | rep1 | cv3 | time: 2.03123617172 sec\n",
      "(0.90588235294117647, 0.91061201974395889, 0.90588235294117647, 0.90289104412846033, 0.94175931803534907)\n",
      "Model: sg | LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) | rep1 | cv4 | time: 2.02504491806 sec\n",
      "(0.89411764705882357, 0.90277310924369747, 0.89411764705882357, 0.89320229092361758, 0.9330780351605179)\n",
      "Model: sg | LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) | rep1 | cv5 | time: 2.02774810791 sec\n",
      "(0.94117647058823528, 0.95168067226890751, 0.94117647058823528, 0.94148294611962446, 0.95967741935483863)\n",
      "Model: sg | MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) | rep1 | cv1 | time: 2.00279808044 sec\n",
      "(0.84269662921348309, 0.85252762219054345, 0.84269662921348309, 0.83839771052417933, 0.89960913108610974)\n",
      "Model: sg | MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) | rep1 | cv2 | time: 2.00092315674 sec\n",
      "(0.91954022988505746, 0.92203369214863462, 0.91954022988505746, 0.91413761953711481, 0.94689586606441478)\n",
      "Model: sg | MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) | rep1 | cv3 | time: 2.00079488754 sec\n",
      "(0.91764705882352937, 0.92149360613810749, 0.91764705882352937, 0.9162332301341588, 0.9475877567275417)\n",
      "Model: sg | MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) | rep1 | cv4 | time: 2.00101804733 sec\n",
      "(0.82352941176470584, 0.85239300021083697, 0.82352941176470584, 0.80824959413194708, 0.8838646041586018)\n",
      "Model: sg | MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) | rep1 | cv5 | time: 1.99992513657 sec\n",
      "(0.97647058823529409, 0.97696078431372557, 0.97647058823529409, 0.97645894577524228, 0.98517872711421095)\n",
      "Model: sg | CalibratedClassifierCV(base_estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "            cv=5, method='sigmoid') | rep1 | cv1 | time: 2.19392824173 sec\n",
      "(0.93258426966292129, 0.93405564472980207, 0.93258426966292129, 0.93030786643863539, 0.95626163259193775)\n",
      "Model: sg | CalibratedClassifierCV(base_estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "            cv=5, method='sigmoid') | rep1 | cv2 | time: 2.17536211014 sec\n",
      "(0.88505747126436785, 0.89174258476154711, 0.88505747126436785, 0.88149824901186069, 0.9263315791898209)\n",
      "Model: sg | CalibratedClassifierCV(base_estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "            cv=5, method='sigmoid') | rep1 | cv3 | time: 2.18602395058 sec\n",
      "(0.90588235294117647, 0.92882352941176471, 0.90588235294117647, 0.91120997605933052, 0.94484709538472988)\n",
      "Model: sg | CalibratedClassifierCV(base_estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "            cv=5, method='sigmoid') | rep1 | cv4 | time: 2.17943906784 sec\n",
      "(0.87058823529411766, 0.88118580765639587, 0.87058823529411766, 0.86821067577967881, 0.91576925172270207)\n",
      "Model: sg | CalibratedClassifierCV(base_estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0),\n",
      "            cv=5, method='sigmoid') | rep1 | cv5 | time: 2.17717313766 sec\n",
      "(0.97647058823529409, 0.97696078431372557, 0.97647058823529409, 0.9757554085463972, 0.98517872711421095)\n",
      "Model: sg | CalibratedClassifierCV(base_estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
      "       n_jobs=-1, penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False),\n",
      "            cv=5, method='sigmoid') | rep1 | cv1 | time: 2.19262099266 sec\n",
      "(0.93258426966292129, 0.93478379298604009, 0.93258426966292129, 0.93010428401942125, 0.95550419729524205)\n",
      "Model: sg | CalibratedClassifierCV(base_estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
      "       n_jobs=-1, penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False),\n",
      "            cv=5, method='sigmoid') | rep1 | cv2 | time: 2.18631720543 sec\n",
      "(0.88505747126436785, 0.89421764213678601, 0.88505747126436785, 0.87000151625105182, 0.92481211100368621)\n",
      "Model: sg | CalibratedClassifierCV(base_estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
      "       n_jobs=-1, penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False),\n",
      "            cv=5, method='sigmoid') | rep1 | cv3 | time: 2.18870210648 sec\n",
      "(0.85882352941176465, 0.86921690415296571, 0.85882352941176465, 0.85167726845476199, 0.90808876017124296)\n",
      "Model: sg | CalibratedClassifierCV(base_estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
      "       n_jobs=-1, penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False),\n",
      "            cv=5, method='sigmoid') | rep1 | cv4 | time: 2.20439124107 sec\n",
      "(0.88235294117647056, 0.88552131963896674, 0.88235294117647056, 0.87725106266282737, 0.92365980000388603)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: sg | CalibratedClassifierCV(base_estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
      "       n_jobs=-1, penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False),\n",
      "            cv=5, method='sigmoid') | rep1 | cv5 | time: 2.19399809837 sec\n",
      "(0.88235294117647056, 0.89453620528671229, 0.88235294117647056, 0.88214752567693755, 0.92428967690979391)\n",
      "Model: sg | MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False) | rep1 | cv1 | time: 11.2314050198 sec\n",
      "(0.898876404494382, 0.9020743301642179, 0.898876404494382, 0.89960406634563939, 0.93513638103190355)\n",
      "Model: sg | MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False) | rep1 | cv2 | time: 11.649985075 sec\n",
      "(0.89655172413793105, 0.90328591115697554, 0.89655172413793105, 0.89038682463221752, 0.93433192443210944)\n",
      "Model: sg | MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False) | rep1 | cv3 | time: 11.2431752682 sec\n",
      "(0.84705882352941175, 0.85686210431885168, 0.84705882352941175, 0.8421480873050976, 0.89933325141573395)\n",
      "Model: sg | MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False) | rep1 | cv4 | time: 11.7681629658 sec\n",
      "(0.96470588235294119, 0.96658823529411764, 0.96470588235294119, 0.96127450980392171, 0.9771142109851787)\n",
      "Model: sg | MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False) | rep1 | cv5 | time: 11.7771730423 sec\n",
      "(0.89411764705882357, 0.90618227088815317, 0.89411764705882357, 0.88960250766973459, 0.92903691290788071)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: sg | MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False) | rep1 | cv1 | time: 29.0486571789 sec\n",
      "(0.8089887640449438, 0.84046865345783495, 0.8089887640449438, 0.79406820267253453, 0.87179398581085799)\n",
      "Model: sg | MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False) | rep1 | cv2 | time: 31.6781761646 sec\n",
      "(0.87356321839080464, 0.83256638921918358, 0.87356321839080464, 0.84617346844631858, 0.91565662955465588)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: sg | MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False) | rep1 | cv3 | time: 32.1805472374 sec\n",
      "(0.84705882352941175, 0.80764318034906268, 0.84705882352941175, 0.82029411764705873, 0.90018276032975897)\n",
      "Model: sg | MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
      "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False) | rep1 | cv4 | time: 30.8439240456 sec\n",
      "(0.91764705882352937, 0.93225152129817446, 0.91764705882352937, 0.90834484401047866, 0.94367639528929848)\n"
     ]
    }
   ],
   "source": [
    "project_dir=\"/Users/zebinkang/Github/scalable_text_analysis/\"  #modify to your project directory\n",
    "evaluate('-w'+project_dir+'test/ -d '+project_dir+'test/data/data.txt -l '+project_dir+'test/data/label.txt -m T -f sg -v freq '+\n",
    "         '-a l1+l2+nb+svmlin+svmsgd+mlp_lbfgs+mlp_sgd+mlp_adam -b None -r 1 -k 5 | tee ../log_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
